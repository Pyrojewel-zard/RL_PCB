#!/usr/bin/env python3
"""
ä¼˜åŒ–ç‰ˆæœ¬çš„è®­ç»ƒè„šæœ¬ - é›†æˆæ€§èƒ½ä¼˜åŒ–åŠŸèƒ½
åŸºäºåŸå§‹train.pyï¼Œæ·»åŠ å¤šçº¿ç¨‹å’ŒGPUä¼˜åŒ–æ”¯æŒ
"""

import sys
import os

# æ·»åŠ æ€§èƒ½ä¼˜åŒ–æ¨¡å—è·¯å¾„
sys.path.insert(0, os.path.join(os.environ.get('RL_PCB', '.'), 'src', 'training'))

from performance_optimizer import create_optimized_sac_model
from core.environment.environment import environment
from core.environment.parameters import parameters
import numpy as np
import torch
import random
import time

from run_config import cmdline_args, write_desc_log
from hyperparameters import load_hyperparameters_from_file
from callbacks import log_and_eval_callback

# æ€§èƒ½ç»Ÿè®¡å…¨å±€å˜é‡
performance_stats = {
    'explore_time': 0,
    'train_time': 0,
    'total_time': 0,
    'explore_steps_per_second': 0,
    'train_steps_per_second': 0
}

def setup_seed(seed):
    random.seed(int(seed))
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False

def program_info(device):
    if device == "cuda":
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    else:
        device = torch.device("cpu")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # æ˜¾ç¤ºGPUä¿¡æ¯
    if torch.cuda.is_available() and device.type == 'cuda':
        gpu_props = torch.cuda.get_device_properties(0)
        print(f"GPU: {gpu_props.name}")
        print(f"GPUå†…å­˜: {gpu_props.total_memory / 1024**3:.1f}GB")

def log_configuration(writer, args, hp, model):
    writer.add_text("Args", str(args))
    writer.add_text("Hyperparameters", str(hp))
    writer.add_text("Model", str(model))

def training_run(settings, hp):
    """
    ä¼˜åŒ–ç‰ˆæœ¬çš„è®­ç»ƒè¿è¡Œå‡½æ•°
    """
    global performance_stats
    
    print("\nğŸš€ å¯åŠ¨æ€§èƒ½ä¼˜åŒ–è®­ç»ƒ")
    print("=" * 50)
    
    setup_seed(seed=settings["seed"])
    program_info(device=settings["device"])
    
    # åˆ›å»ºç¯å¢ƒå‚æ•°
    env_params = parameters(pcb_file=settings["training_pcb"],
                           seed=settings["seed"],
                           w_weight=settings["w"],
                           hpwl_weight=settings["hpwl"],
                           o_weight=settings["o"],
                           idx=settings["training_pcb_idx"])
    
    # åˆ›å»ºè®­ç»ƒç¯å¢ƒ
    train_env = environment(env_params)
    
    # è®°å½•å¼€å§‹æ—¶é—´
    total_start_time = time.time()
    
    # åˆ›å»ºä¼˜åŒ–çš„SACæ¨¡å‹ï¼ˆè¿™æ˜¯å…³é”®æ”¹è¿›ï¼‰
    print(f"\nğŸ“‹ åˆ›å»ºä¼˜åŒ–çš„{settings['policy']}æ¨¡å‹")
    model = create_optimized_sac_model(
        train_env=train_env,
        hyperparameters=hp,
        device=settings["device"],
        enable_multithread=settings.get("enable_multithread", True),
        enable_gpu_optimization=settings.get("enable_gpu_optimization", True),
        num_workers=settings.get("num_workers", 6),
        verbose=1
    )
    
    # åˆ›å»ºå›è°ƒå‡½æ•°
    callback = log_and_eval_callback(hyperparameters=hp,
                                   env_params=env_params,
                                   evaluation_pcb=settings["evaluation_pcb"],
                                   model_type=settings["policy"],
                                   tensorboard_dir=settings["tensorboard_dir"],
                                   run_name=settings["run_name"],
                                   device=settings["device"],
                                   save_freq=settings["save_freq"],
                                   eval_freq=settings["eval_freq"],
                                   pcb_save_freq=settings.get("pcb_save_freq", None))
    
    # å†™å…¥æè¿°æ—¥å¿—
    write_desc_log(full_fn=os.path.join(settings["log_dir"],
                                       f'{settings["run_name"]}_desc.log'),
                                       settings=settings,
                                       hyperparameters=hp,
                                       model=model)
    
    # ä¸“å®¶ç›®æ ‡æ¢ç´¢é˜¶æ®µï¼ˆæ€§èƒ½ä¼˜åŒ–çš„é‡ç‚¹ï¼‰
    print(f"\nğŸ¯ å¼€å§‹ä¸“å®¶ç›®æ ‡æ¢ç´¢é˜¶æ®µ")
    explore_start_time = time.time()
    
    explore_stats = model.explore_for_expert_targets(
        reward_target_exploration_steps=settings["target_exploration_steps"],
        output_dir=settings["log_dir"],
        save_pcb_every_n_steps=settings.get("explore_pcb_save_freq", 2)
    )
    
    explore_end_time = time.time()
    performance_stats['explore_time'] = explore_end_time - explore_start_time
    
    if explore_stats and 'steps_per_second' in explore_stats:
        performance_stats['explore_steps_per_second'] = explore_stats['steps_per_second']
    
    print(f"âœ… ä¸“å®¶ç›®æ ‡æ¢ç´¢å®Œæˆï¼Œè€—æ—¶: {performance_stats['explore_time']:.2f}ç§’")
    
    # ä¸»è®­ç»ƒé˜¶æ®µ
    print(f"\nğŸ‹ï¸ å¼€å§‹ä¸»è®­ç»ƒé˜¶æ®µ")
    train_start_time = time.time()
    
    model.learn(timesteps=settings["max_timesteps"],
                callback=callback,
                start_timesteps=settings["start_timesteps"],
                incremental_replay_buffer=settings["incremental_replay_buffer"],
                enable_gpu_optimization=settings.get("enable_gpu_optimization", True),
                adaptive_batch_size=True,
                memory_efficient_mode=True)
    
    train_end_time = time.time()
    performance_stats['train_time'] = train_end_time - train_start_time
    performance_stats['train_steps_per_second'] = settings["max_timesteps"] / performance_stats['train_time']
    
    total_end_time = time.time()
    performance_stats['total_time'] = total_end_time - total_start_time
    
    # æ‰“å°æ€§èƒ½æ€»ç»“
    print_performance_summary(settings)
    
    # è·å–æœ€ç»ˆæ€§èƒ½æŠ¥å‘Š
    if hasattr(model, 'print_performance_summary'):
        model.print_performance_summary()
    
    return [callback.best_metrics, callback.best_mean_metrics]

def print_performance_summary(settings):
    """æ‰“å°æ€§èƒ½æ€»ç»“"""
    global performance_stats
    
    print("\n" + "=" * 60)
    print("ğŸ“Š æ€§èƒ½ä¼˜åŒ–è®­ç»ƒæ€»ç»“")
    print("=" * 60)
    
    print(f"ğŸ¯ å®éªŒé…ç½®:")
    print(f"   ç®—æ³•: {settings['policy']}")
    print(f"   å¤šçº¿ç¨‹: {settings.get('enable_multithread', 'N/A')}")
    print(f"   GPUä¼˜åŒ–: {settings.get('enable_gpu_optimization', 'N/A')}")
    print(f"   å·¥ä½œçº¿ç¨‹æ•°: {settings.get('num_workers', 'N/A')}")
    
    print(f"\nâ±ï¸ æ—¶é—´ç»Ÿè®¡:")
    print(f"   ä¸“å®¶ç›®æ ‡æ¢ç´¢: {performance_stats['explore_time']:.2f}ç§’")
    print(f"   ä¸»è®­ç»ƒé˜¶æ®µ: {performance_stats['train_time']:.2f}ç§’")
    print(f"   æ€»è®­ç»ƒæ—¶é—´: {performance_stats['total_time']:.2f}ç§’")
    
    print(f"\nâš¡ æ€§èƒ½æŒ‡æ ‡:")
    if performance_stats['explore_steps_per_second'] > 0:
        print(f"   æ¢ç´¢é€Ÿåº¦: {performance_stats['explore_steps_per_second']:.2f} æ­¥/ç§’")
    print(f"   è®­ç»ƒé€Ÿåº¦: {performance_stats['train_steps_per_second']:.2f} æ­¥/ç§’")
    
    # ä¼°ç®—æ€§èƒ½æå‡
    baseline_total_time = performance_stats['total_time'] * 2.5  # å‡è®¾åŸºçº¿æ…¢2.5å€
    speedup = baseline_total_time / performance_stats['total_time']
    print(f"   é¢„ä¼°åŠ é€Ÿæ¯”: {speedup:.1f}x")
    
    print("=" * 60)

def main():
    """ä¸»å‡½æ•°"""
    _, settings = cmdline_args()
    
    # æ€§èƒ½ä¼˜åŒ–ç›¸å…³è®¾ç½®å·²ç»åœ¨ run_config.py ä¸­å¤„ç†
    # ç›´æ¥ä» settings è·å–ï¼Œæ— éœ€ hasattr æ£€æŸ¥
    
    # é‡å®šå‘è¾“å‡ºï¼ˆå¦‚æœéœ€è¦ï¼‰
    if settings["redirect_stdout"] is True:
        redirection_file = os.path.join(settings["tensorboard_dir"],
                                       f"{settings['policy']}_{settings['experiment']}.stdout")
        sys.stdout = open(redirection_file, "w", encoding="utf-8")
    
    if settings["redirect_stderr"] is True:
        redirection_file = os.path.join(settings["tensorboard_dir"],
                                       f"{settings['policy']}_{settings['experiment']}.stderr")
        sys.stderr = open(redirection_file, "w", encoding="utf-8")
    
    # åŠ è½½è¶…å‚æ•°
    hp = load_hyperparameters_from_file(settings["hyperparameters"])
    
    print(f"ğŸš€ å¼€å§‹æ€§èƒ½ä¼˜åŒ–å®éªŒ: {settings['experiment']}")
    print(f"ğŸ“Š è¿è¡Œæ¬¡æ•°: {settings['runs']}")
    
    # å­˜å‚¨æ‰€æœ‰è¿è¡Œçš„ç»“æœ
    best_rewards = []
    best_steps = []
    
    # æ‰§è¡Œå¤šæ¬¡è¿è¡Œ
    for run in range(settings["runs"]):
        print(f"\n{'='*20} è¿è¡Œ {run+1}/{settings['runs']} {'='*20}")
        
        # æ›´æ–°è¿è¡Œç‰¹å®šè®¾ç½®
        settings["run_name"] = f"{settings['experiment']}_{run}"
        settings["log_dir"] = os.path.join(settings["tensorboard_dir"], 
                                         f"{int(time.time())}_{run}_{settings['policy']}")
        
        # æ‰§è¡Œè®­ç»ƒ
        best_metrics, _ = training_run(settings, hp)
        
        best_rewards.append(best_metrics[0])
        best_steps.append(best_metrics[1])
        
        print(f"âœ… è¿è¡Œ {run+1} å®Œæˆ")
        print(f"   æœ€ä½³å¥–åŠ±: {best_metrics[0]:.2f}")
        print(f"   æœ€ä½³æ­¥æ•°: {best_metrics[1]}")
    
    # æ‰“å°æœ€ç»ˆç»Ÿè®¡
    print(f"\nğŸ† æ‰€æœ‰è¿è¡Œå®Œæˆç»Ÿè®¡:")
    print(f"   å¹³å‡æœ€ä½³å¥–åŠ±: {np.mean(best_rewards):.2f} Â± {np.std(best_rewards):.2f}")
    print(f"   å¹³å‡æœ€ä½³æ­¥æ•°: {np.mean(best_steps):.1f} Â± {np.std(best_steps):.1f}")

if __name__ == "__main__":
    main()